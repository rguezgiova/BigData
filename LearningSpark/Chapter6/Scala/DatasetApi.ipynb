{"cells":[{"cell_type":"markdown","source":["## Datasets: Lenguaje de consulta DataFrame vs Lambdas\n\nLa API de Datasets ofrece la opción de utilizar el lenguaje de consultas como las transformaciones de RDD"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf45e3ad-5b5e-4f4d-ac24-30c0f83fdf2d"}}},{"cell_type":"code","source":["%scala\ncase class Person(id: Integer, firstName: String, middleName: String, lastName: String, gender: String, birthDate: String, ssn: String, salary: String)\n\nval personDs = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\", \":\").csv(\"dbfs:/databricks-datasets/learning-spark-v2/people/people-with-header-10m.txt\").as[Person]\n\npersonDs.cache().count"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e4ded89-21d8-427e-8598-4033b94fd020"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"personDs","typeStr":"org.apache.spark.sql.Dataset[Person]","schema":{"type":"struct","fields":[{"name":"id","type":"integer","nullable":true,"metadata":{}},{"name":"firstName","type":"string","nullable":true,"metadata":{}},{"name":"middleName","type":"string","nullable":true,"metadata":{}},{"name":"lastName","type":"string","nullable":true,"metadata":{}},{"name":"gender","type":"string","nullable":true,"metadata":{}},{"name":"birthDate","type":"timestamp","nullable":true,"metadata":{}},{"name":"ssn","type":"string","nullable":true,"metadata":{}},{"name":"salary","type":"integer","nullable":true,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">defined class Person\npersonDs: org.apache.spark.sql.Dataset[Person] = [id: int, firstName: string ... 6 more fields]\nres11: Long = 10000000\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">defined class Person\npersonDs: org.apache.spark.sql.Dataset[Person] = [id: int, firstName: string ... 6 more fields]\nres11: Long = 10000000\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Consulta DataFrame DSL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bce5e857-0bc4-49f6-9b8b-cfcbb718417a"}}},{"cell_type":"code","source":["%scala\nprintln(personDs.filter($\"firstName\" === \"Nell\").distinct().count)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"928eeea6-b886-45ce-a6ce-0e17b0fc9480"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">1218\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1218\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Dataset con lambda"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b06bd9ca-3815-4585-8b3b-7dda833f8686"}}},{"cell_type":"code","source":["%scala\nprintln(personDs.filter(x => x.firstName == \"Nell\").distinct().count)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f0937bac-0766-4e64-94ef-57f352fe8096"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">1218\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1218\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["- Ventaja del uso de lambdas\n  - Bueno para datos semiestructurados\n  - Muy potente\n- Desventajas\n  - Catalyst no puede interpretar las lambdas hasta el tiempo de ejecución. \n  - Las lambdas son opacas para Catalyst. Como no sabe lo que está haciendo una lambda, no puede trasladarla a otra parte del procesamiento.\n  - Saltar entre las lambdas y la API de consulta de DataFrame puede perjudicar el rendimiento.\n  - Trabajar con lambdas significa que tenemos que `deserializar` del formato de Tungsteno a un objeto y luego volver a serializar al formato de Tungsteno cuando la lambda haya terminado.\n  \nSi tienes que usar lambdas, encadenarlas puede ayudar."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0791227-2183-44f4-b1cb-528728a49903"}}},{"cell_type":"code","source":["%scala\nimport java.util.Calendar\n\nval earliestYear = Calendar.getInstance.get(Calendar.YEAR) - 40\n\npersonDs.filter(x => x.birthDate.split(\"-\")(0).toInt > earliestYear)\n        .filter($\"salary\" > 80000)\n        .filter(x => x.lastName.startsWith(\"J\"))\n        .filter($\"firstName\".startsWith(\"D\")).count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6203756-7534-4459-b78e-2d78b6d4f263"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">import java.util.Calendar\nearliestYear: Int = 1982\nres15: Long = 1896\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">import java.util.Calendar\nearliestYear: Int = 1982\nres15: Long = 1896\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\nimport org.apache.spark.sql.functions._\n\npersonDs.filter(year($\"birthDate\") > earliestYear)\n        .filter($\"salary\" > 80000)\n        .filter($\"lastName\".startsWith(\"J\"))\n        .filter($\"firstName\".startsWith(\"D\")).count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"65657b57-4058-4285-ae89-9ad0f3700b03"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">import org.apache.spark.sql.functions._\nres16: Long = 1896\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">import org.apache.spark.sql.functions._\nres16: Long = 1896\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DatasetApi","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3646933032612893}},"nbformat":4,"nbformat_minor":0}
